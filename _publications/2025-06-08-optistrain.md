---
title: "Optistrain: A vision- and microfluidics-based tactile sensor with high spatial and temporal resolution"
collection: publications
category: conferences
# permalink: /publication/2025-optistrain-haptics
excerpt: 'This paper presents Optistrain, a novel tactile sensor that combines vision and microfluidics technologies to achieve high spatial and temporal resolution for haptic sensing applications.'
date: 2025-06-08
venue: 'IEEE World Haptics Conference'
# paperurl: 'http://academicpages.github.io/files/optistrain-haptics-2025.pdf'
citation: 'E. Harber, C. P. Johnson, A. Liebman, A. Psychoyos, M. Whidby, S.-M. Kang, J. Peñaloza, A. T. Bender, J. D. Posner, and V. J. Santos. (2025). &quot;Optistrain: A vision- and microfluidics-based tactile sensor with high spatial and temporal resolution.&quot; <i>IEEE World Haptics Conference</i>. Work in Progress.'
---
This work introduces OptiStrain, the first multimodal tactile sensor that integrates vision-based and microfluidics-based sensing mechanisms into a single elastomeric fingerpad. The sensor addresses a key limitation in current tactile sensing technology by combining high spatial resolution (achieved through camera-based optical flow tracking of surface deformation) with high temporal resolution (achieved through embedded liquid metal strain gauges).

**Key Contributions:**
- **Dual-modality design**: Combines vision-based sensing (similar to GelSight sensors) with liquid metal strain gauges for comprehensive tactile perception
- **Enhanced force estimation**: Multimodal approach reduces force estimation error by 12-14% compared to single-modality approaches
- **High-resolution capabilities**: Achieves spatial resolution of 25-100 points/cm² and temporal resolution under 1000 Hz, matching human touch capabilities
- **Micron-scale sensitivity**: Demonstrates ability to detect strains as small as ±0.12 μm through piezoelectric actuation experiments

The sensor features a deformable elastomeric fingerpad with embedded liquid metal strain gauges, observed by a camera with fisheye lens. This design enables simultaneous capture of contact area, force distribution, and rapid mechanical changes. Experimental validation shows sub-Newton force estimation accuracy across a 12N range, with LSTM networks successfully integrating both data streams for improved performance.

This research represents a significant step toward replicating human-like tactile sensing in robotic systems, with potential applications in prosthetics, robotic manipulation, and human-computer interaction.